{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4a892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = \".\\\\signlang\\\\signlang\" #MUST HAVE SIGNLANG DIR in current directory as this file python file\n",
    "\n",
    "\n",
    "test_directory = os.path.join(base_dir,\"test\")\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale= 1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale= 1.0/255)\n",
    "\n",
    "train_directory = os.path.join(base_dir,\"train\")\n",
    "train_generator = train_datagen.flow_from_directory(train_directory, target_size=(150,150), \n",
    "                                                    shuffle=True, batch_size=20, class_mode='categorical')\n",
    "\n",
    "\n",
    "val_directory = os.path.join(base_dir,\"val\")\n",
    "val_generator = test_datagen.flow_from_directory(val_directory, target_size=(150,150), batch_size=20, \n",
    "                                                 shuffle=True, class_mode='categorical')\n",
    "\n",
    "test_directory = os.path.join(base_dir,\"test\")\n",
    "test_generator = test_datagen.flow_from_directory(test_directory, target_size=(150,150), batch_size=20, \n",
    "                                                 shuffle=True, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef58be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying randomised batch of images within datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data_batch, label_batch in train_generator:\n",
    "    break\n",
    "\n",
    "    \n",
    "fig=plt.figure(figsize=(20,20))\n",
    "columns = 3\n",
    "rows = 3\n",
    "for i in range (1,10):\n",
    "    img = data_batch[i]\n",
    "    ax = fig.add_subplot(rows, columns, i)\n",
    "    plt.subplots_adjust(hspace=None, wspace = 0.01)\n",
    "    ax.title.set_text(str(i)+ \"label=\" +str(label_batch[i]))\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd71b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "\n",
    "from keras import models, layers\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(150,150,3)))\n",
    "network.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "network.add(layers.Flatten())\n",
    "network.add(layers.Dense(128, activation=\"relu\"))\n",
    "network.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "network.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=1e-4), metrics=[\"accuracy\"])\n",
    "\n",
    "network.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f961ef28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = network.fit_generator(train_generator, steps_per_epoch=20, epochs=20, \n",
    "                             validation_data=val_generator, validation_steps=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094aec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING AND LOADING history of fitting the model.\n",
    "import pickle\n",
    "dictionary_data = history.history\n",
    "history_file = open(\"ASL_History_Data\", \"wb\")\n",
    "pickle.dump(dictionary_data, history_file)\n",
    "history_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "history_file = open(\"ASL_History_Data\", \"rb\")\n",
    "history = pickle.load(history_file)\n",
    "history_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c5327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying results onto metaplot graph\n",
    "Training_history_info = [history[\"loss\"], history[\"accuracy\"]]\n",
    "Validation_history_info = [history[\"val_loss\"], history[\"val_accuracy\"]]\n",
    "\n",
    "epochs = range(1,len(Training_history_info[0])+1)\n",
    "\n",
    "plt.plot(epochs,Training_history_info[0],'b', label='Train Loss')\n",
    "plt.plot(epochs,Validation_history_info[0], 'c', label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot(epochs,Training_history_info[1],'b', label='Train Accuracy')\n",
    "plt.plot(epochs,Validation_history_info[1], 'c', label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = network.evaluate(test_generator, verbose=2)\n",
    "print (\"Overall accuracy: {0}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74a668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
